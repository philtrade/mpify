{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `mpify` to Train Fastai2/Course-V4 Examples \"Distributedly\" on Multiple GPUs\n",
    "\n",
    "###  To train a `fastai2` learner on multiple processes inside a Jupyter notebook\n",
    "\n",
    "The key is to ensure each process has its own copy of: the model, the access to its GPU, and dataloader.\n",
    "\n",
    "The `DataLoader` must be re-created fresh on each process, because the CUDA GPU context it might initialize cannot be reused in another process.\n",
    "CUDA PyTorch tensors created in the parent Jupyter process should not be passed to the subprocesses, otherwise it will incur 600MB memory, *per subprocess*, on the original GPU associated with the tensor.\n",
    "\n",
    "For other variables (`path` of untar'ed dataset, or `df` a loaded DataFrame), or the many helper functions, they can be passed to the distributed training API `in_torchddp()` via `imports=` and `need=` parameters.\n",
    "\n",
    "### Quick links to chapters `mpify`ed\n",
    "\n",
    "[01_intro.ipynb](/examples/fastai2_course-v4_01_intro_distrib.ipynb)\n",
    "\n",
    "[05_pet_breeds.ipynb](/examples/fastai2_course-v4_05_pet_breeds_distrib.ipynb)\n",
    "\n",
    "[06_multicat.ipynb](/examples/fastai2_course-v4_06_multicat_distrib.ipynb)\n",
    "\n",
    "[07_sizing_and_tta.ipynb](/examples/fastai2_course-v4_07_sizing_tta_distrib.ipynb)\n",
    "\n",
    "[08_collab.ipynb](/examples/fastai2_course-v4_08_collab_distrib.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are distributed training of examples correspond to fastai2 course-v4 <a href='https://github.com/fastai/course-v4/blob/master/nbs/05_pet_breeds.ipynb' target='_blank'>`05_pet_breeds.ipynb`</a>\n",
    "\n",
    "### 05_pet_breeds.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T10:13:21.085172Z",
     "start_time": "2020-07-19T10:13:21.047397Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from fastai2.data import *\n",
    "from fastai2.vision.all import *\n",
    "\n",
    "path = untar_data(URLs.PETS)\n",
    "\n",
    "# The above are defined earlier in the notebook, included here for convenience\n",
    "\n",
    "from mpify import in_torchddp\n",
    "ngpus = 3\n",
    "\n",
    "def fine_tune(learn:Learner, nepochs, *args, **kwargs):\n",
    "    with learn.distrib_ctx(): learn.fine_tune(nepochs, *args, **kwargs)\n",
    "    return learn\n",
    "    \n",
    "def one_cycle(learn:Learner, nepochs, *args, **kwargs):\n",
    "    with learn.distrib_ctx(): learn.fit_one_cycle(nepochs, *args, **kwargs)\n",
    "    return learn\n",
    "\n",
    "def trainer(train_fn, nepochs, *args, load:str=None, **kwargs):\n",
    "    pets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                     get_items = get_image_files, \n",
    "                     splitter  = RandomSplitter(seed=42),\n",
    "                     get_y     = using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n",
    "                     item_tfms = Resize(460),\n",
    "                     batch_tfms= aug_transforms(size=224, min_scale=0.75))\n",
    "    dls = pets.dataloaders(path/\"images\")\n",
    "    \n",
    "    learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "    \n",
    "    if load:\n",
    "        learn.load(load)\n",
    "        print(f'Model and state loaded from {load}')\n",
    "\n",
    "    learn = train_fn(learn, nepochs, *args, **kwargs)\n",
    "    return learn\n",
    "\n",
    "imports='''\n",
    "from utils import *\n",
    "from fastai2.data import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "need='path fine_tune one_cycle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First are items defined earlier on in the notebook, but will be needed to construct the Dataloader, and during training.\n",
    "\n",
    "In this chapter, `Learner.fine_tune()` and `Learner.fit_one_cycle()` are introduced and interleaved throughout.\n",
    "\n",
    "Thus I created a wrapper for each, and passed them via `in_torchddp()` as the first positional argument after `trainer` itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T10:13:21.085172Z",
     "start_time": "2020-07-19T10:13:21.047397Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = in_torchddp(ngpus, trainer, fine_tune, 1, base_lr=0.1, imports=imports, need=need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_min,lr_steep = learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to perform learn.fine_tune(2, base_lr=3e-3) on multiple GPUs in DDP\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer, fine_tune, 2, base_lr=3e-3, imports=imports, need=need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: learn.fit_one_cycle(3, 3e-3) on multiple GPUs in DDP\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer, one_cycle, 3, 3e-3, imports=imports, need=need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: learn.fit_one_cycle(6, lr_max=1e-5) on multiple GPUs in DDP\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer, one_cycle, 6, lr_max=1e-5, imports=imports, need=need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05 pets breeds: Discriminative Learning Rates\n",
    "\n",
    "To perform multiple stages of training, e.g.:\n",
    "\n",
    "```python\n",
    "    learn.fit_one_cycle(3, 3e-3)\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(12, lr_max=slice(1e-6,1e-4))\n",
    "```\n",
    "\n",
    "we need to *save the model state* before subsequent calls to `fit_one_cycle()`.  Then wel tell `in_torchddp()` to load from that file using 'load=file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = in_torchddp(ngpus, trainer, one_cycle, 3, 3e-3,\n",
    "                    imports=imports, need=\"one_cycle\")\n",
    "learn.unfreeze()\n",
    "learn.save(\"after_unfreeze\", with_opt=True, pickle_protocol=4)\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer, one_cycle, 12, lr_max=slice(1e-6,1e-4),\n",
    "                    load=\"after_unfreeze\", imports=imports, need=\"one_cycle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05 pets breeds: Deeper Architectures\n",
    "\n",
    "To do:\n",
    "```python\n",
    "from fastai2.callback.fp16 import *\n",
    "learn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16()\n",
    "learn.fine_tune(6, freeze_epochs=3)\n",
    "```\n",
    "\n",
    "We modify `trainer()` to write a new function `trainer_fp16_resnet50()`, replace `resnet34` with `resnet50`, and add `.to_fp16()`.  Then pass it to `in_torchddp()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer_fp16_resnet50(train_fn, nepochs, *args, load:str=None, **kwargs):\n",
    "\n",
    "    path = untar_data(URLs.PETS)\n",
    "\n",
    "    pets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                     get_items = get_image_files, \n",
    "                     splitter  = RandomSplitter(seed=42),\n",
    "                     get_y     = using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n",
    "                     item_tfms = Resize(460),\n",
    "                     batch_tfms= aug_transforms(size=224, min_scale=0.75))\n",
    "    dls = pets.dataloaders(path/\"images\")\n",
    "    \n",
    "    # Use resnet50, and half precision.\n",
    "    learn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16()\n",
    "    \n",
    "    if load:\n",
    "        learn.load(load)\n",
    "        print(f'Model and state loaded from {load}')\n",
    "\n",
    "    learn = train_fn(learn, nepochs, *args, **kwargs)\n",
    "    return learn\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer_fp16_resnet50, fine_tune, 6, freeze_epochs=3,\n",
    "                    imports=imports, need=\"fine_tune\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}