{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `mpify` to Training \"Distributedly\" Fastai2/Course-V4 Jupyter Notebooks\n",
    "\n",
    "###  To train a `fastai2` learner on multiple processes inside a Jupyter notebook ...\n",
    "\n",
    "The `DataLoaders` must be re-created fresh on each process, because in its instantiation process, it would initialize a CUDA GPU context, which cannot be reused in another process.\n",
    "\n",
    "Thus in all the examples here, both `DataBlock` and `DataLoaders` (often noted as `dls`) are all created inside the target function body.  For other variables (`path` of untar'ed dataset, or `df` a loaded DataFrame), or the many helper functions, they can be passed to the distributed training API `in_torchddp()` via `imports=` and `need=` parameters.\n",
    "\n",
    "### Quick links to chapters `mpify`ed\n",
    "\n",
    "[01_intro.ipynb](/examples/fastai2_course-v4_01_intro_distrib.ipynb)\n",
    "\n",
    "[05_pet_breeds.ipynb](/examples/fastai2_course-v4_05_pet_breeds_distrib.ipynb)\n",
    "\n",
    "[06 multicat.ipynb](/examples/fastai2_course-v4_06_multicat_distrib.ipynb)\n",
    "\n",
    "[07 Sizing and TTA.ipynb](/examples/fastai2_course-v4_07_sizing_tta_distrib.ipynb)\n",
    "\n",
    "[08 Collab.ipynb](/examples/fastai2_course-v4_08_collab_distrib.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are distributed training of examples correspond to fastai2 course-v4 <a href='https://github.com/fastai/course-v4/blob/master/nbs/06_multicat.ipynb' target='_blank'>`06_multicat.ipynb`</a>\n",
    "\n",
    "### <a name='06multicat'></a> 06 Multicat  - Multi-Label Classifications\n",
    "\n",
    "The Chapter 6 \"Multi-Label Classification\" notebook builds a `learn` object is from\n",
    "several pieces across many cells. \n",
    "\n",
    "`DataBlock` object needs `path`, and a few other functions: `get_x, get_y, splitter`, and `dls` needs `df`.  So we group some of them together in `need=`.\n",
    "\n",
    "I do notice accuracy degradation using the same 3 epochs, of `0.81`, as oppose to the `0.95` range in the book.\n",
    "\n",
    "So what can we do?  Save the model after the first training, then use `load=filename` flag, tweak `nepochs` and `freeze_epochs=` values and call `in_torchddp()` again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are defined earlier in the notebook:\n",
    "from utils import *\n",
    "from fastai2.vision.all import *\n",
    "\n",
    "path = untar_data(URLs.PASCAL_2007)\n",
    "df = pd.read_csv(path/'train.csv')\n",
    "\n",
    "def get_x(r): return path/'train'/r['fname']\n",
    "def get_y(r): return r['labels'].split(' ')\n",
    "def splitter(df):\n",
    "    train = df.index[~df['is_valid']].tolist()\n",
    "    valid = df.index[df['is_valid']].tolist()\n",
    "    return train,valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chapter defines the above variables and functions across several cells.\n",
    "\n",
    "The target function accepts a `load` parameter for loading saved model state.  It uses `resnet50`, and the `Learner.fine_tune()` training method, with `nepochs` as the position argument.  Other training arguments like `base_lr`, `freeze_epochs` are handled by `**kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to perform those trainings in DDP\n",
    "\n",
    "from mpify import in_torchddp\n",
    "ngpus = 3  # Modify to your taste\n",
    "\n",
    "def train_multicat(nepochs, *args, load:str=None, **kwargs):\n",
    "    dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n",
    "                   splitter=splitter,\n",
    "                   get_x=get_x, \n",
    "                   get_y=get_y,\n",
    "                   item_tfms = RandomResizedCrop(128, min_scale=0.35))\n",
    "    dls = dblock.dataloaders(df)\n",
    "    \n",
    "    learn = cnn_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.2))\n",
    "    \n",
    "    if load: learn.load(load); print(f'Model and state loaded from {load}')\n",
    "\n",
    "    with learn.distrib_ctx():\n",
    "        learn.fine_tune(nepochs, *args, **kwargs)\n",
    "        \n",
    "    return learn\n",
    "        \n",
    "imports='''\n",
    "from utils import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "need=\"path df get_x get_y splitter\"\n",
    "\n",
    "learn = in_torchddp(ngpus, train_multicat, 3, base_lr=3e-3, freeze_epochs=4,\n",
    "                    imports=imports, need=need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The next training uses a different dataset `BIWI_HEAD_POSE`, and a different sets of helper routines.\n",
    "And I missed `img2pose` in the first pass scooping them out.   Thanks to a `NameError` exception, I can simply add it to `need=`.\n",
    "\n",
    "#### To Train Distributedly More Than Once ...\n",
    "What if training a few epochs seem not getting good enough accuracy, how to train \"distributedly\" again in Jupyter?\n",
    "\n",
    "Because `mpify.in_torchddp()` returns the resulting `Learner` object to the main Jupyter shell, user can save its state to a file, and use it in subsequent new `in_torchddp()` calls where a new group of processes will be spawned from scratch, and start training after `load`ing from the file -- *as demonstrated below*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.BIWI_HEAD_POSE)\n",
    "\n",
    "def img2pose(x): return Path(f'{str(x)[:-7]}pose.txt')\n",
    "\n",
    "cal = np.genfromtxt(path/'01'/'rgb.cal', skip_footer=6)\n",
    "def get_ctr(f):\n",
    "    ctr = np.genfromtxt(img2pose(f), skip_header=3)\n",
    "    c1 = ctr[0] * cal[0][0]/ctr[2] + cal[0][2]\n",
    "    c2 = ctr[1] * cal[1][1]/ctr[2] + cal[1][2]\n",
    "    return tensor([c1,c2])\n",
    "\n",
    "def train_biwi(nepochs, *args, load:str=None, **kwargs):\n",
    "    biwi = DataBlock(\n",
    "        blocks=(ImageBlock, PointBlock),\n",
    "        get_items=get_image_files,\n",
    "        get_y=get_ctr,\n",
    "        splitter=FuncSplitter(lambda o: o.parent.name=='13'),\n",
    "        batch_tfms=[*aug_transforms(size=(240,320)), \n",
    "                    Normalize.from_stats(*imagenet_stats)])\n",
    "\n",
    "    dls = biwi.dataloaders(path)\n",
    "\n",
    "    learn = cnn_learner(dls, resnet18, y_range=(-1,1))\n",
    "    if load: learn.load(load); print(f'Model and state loaded from {load}')\n",
    "\n",
    "    lr = 1e-2\n",
    "    with learn.distrib_ctx(): learn.fine_tune(nepochs, lr)\n",
    "    return learn\n",
    "\n",
    "imports='''\n",
    "from utils import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.distributed import *\n",
    "improt numpy as np\n",
    "'''\n",
    "\n",
    "need=\"path cal get_ctr img2pose\"\n",
    "\n",
    "learn = in_torchddp(ngpus, train_biwi, 3, imports=imports, need=need)\n",
    "\n",
    "# Not satisfied with the accuracy?  Save then train 5 more epochs, starting from the current state\n",
    "learn.save('biwi_after3')\n",
    "learn = in_torchddp(ngpus, train_biwi, 5, load='biwi_after3', imports=imports, need=need)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}