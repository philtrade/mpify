{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `mpify` to Train Fastai2/Course-V4 Examples \"Distributedly\" on Multiple GPUs\n",
    "\n",
    "###  To train a `fastai2` learner on multiple processes inside a Jupyter notebook\n",
    "1. Ensure each process has its own copy of: the model, the access to its GPU, and dataloader.\n",
    "\n",
    "    * The `DataLoader` must be re-created fresh on each process, because the CUDA GPU context it might initialize cannot be reused in another process.\n",
    "    CUDA PyTorch tensors created in the parent Jupyter process should not be passed to the subprocesses, otherwise it will incur 600MB memory, *per subprocess*, on the original GPU associated with the tensor.\n",
    "\n",
    "    * For other variables (`path` of untar'ed dataset, or `df` a loaded DataFrame), or the many helper functions, they can be passed to the distributed training API `in_torchddp()` via `imports=` and `need=` parameters.\n",
    "\n",
    "2. In each process `from fastai2.distributed import *`, and surround the fitting function `with learn.distrib_ctx()`.\n",
    "\n",
    "### Quick links to course-v4 chapters `mpify`-ed:\n",
    "\n",
    "[01_intro.ipynb](/examples/fastai2_course-v4-01_intro_distrib.ipynb)\n",
    "\n",
    "[05_pet_breeds.ipynb](#01petbreeds)\n",
    "\n",
    "[06_multicat.ipynb](/examples/fastai2_course-v4_06_multicat_distrib.ipynb)\n",
    "\n",
    "[07_sizing_and_tta.ipynb](/examples/fastai2_course-v4_07_sizing_tta_distrib.ipynb)\n",
    "\n",
    "[08_collab.ipynb](/examples/fastai2_course-v4_08_collab_distrib.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are the distributed training examples correspond to fastai2 course-v4 <a href='https://github.com/fastai/course-v4/blob/master/nbs/07_sizing_and_tta.ipynb' target='_blank'>`07_sizing_and_tta.ipynb`</a>\n",
    "\n",
    "### <a name='07sizingtta'></a> 07 Sizing and TTA\n",
    "\n",
    "In this chapter, `Imagenette` dataset is trained with incremental optimization.  Then training tricks are added one by one. First normalization, then progressive resizing, then a choice between `learn.fine_tune()` or `learn.fit_one_cycle()`.\n",
    "\n",
    "For clarity, I created TWO pairs of `get_dls*()` and `train_imgnette*()`:\n",
    "\n",
    "First pair is for the base case: no normalization, one size, and uses `fit_one_cycle().\n",
    "\n",
    "The second pair adds normalization, allow custom batch size and image size, choice of `fit_one_cycle` vs `fine_tune`, and loading from a saved model state file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpify import in_torchddp\n",
    "from fastai2.vision.all import *\n",
    "\n",
    "path = untar_data(URLs.IMAGENETTE)\n",
    "\n",
    "#  First Pair of dataloader factory and training function, all hard coded values.\n",
    "def get_dls_basic():\n",
    "    dblock = DataBlock(blocks=(ImageBlock(), CategoryBlock()),\n",
    "                       get_items=get_image_files,\n",
    "                       get_y=parent_label,\n",
    "                       item_tfms=Resize(460),\n",
    "                       batch_tfms=aug_transforms(size=224, min_scale=0.75))\n",
    "    dls = dblock.dataloaders(path, bs=64)\n",
    "    return dls\n",
    "\n",
    "def train_imgnette_basic(nepochs, lr, *args, **kwargs):\n",
    "    dls = get_dls_basic() \n",
    "    model = xresnet50()\n",
    "    learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n",
    "    \n",
    "    with learn.distrib_ctx():\n",
    "        learn.fit_one_cycle(nepochs, lr)\n",
    "    \n",
    "    return learn\n",
    "\n",
    "# Second pair allows several customizable parameters\n",
    "def get_dls_general(bs, size):\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                       get_items=get_image_files,\n",
    "                       get_y=parent_label,\n",
    "                       item_tfms=Resize(460),\n",
    "                       batch_tfms=[*aug_transforms(size=size, min_scale=0.75),\n",
    "                            Normalize.from_stats(*imagenet_stats)])\n",
    "    return dblock.dataloaders(path, bs=bs)\n",
    "\n",
    "def train_imgnette_general(nepochs, lr, dls_bs, dls_size, *args, fine_tune:bool=False, load:str=None, **kwargs):\n",
    "    dls = get_dls_general(dls_bs, dls_size) \n",
    "    model = xresnet50()\n",
    "    learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n",
    "    \n",
    "    if load:\n",
    "        learn.load(load)\n",
    "        print(f\"Model state loaded from {load}\")\n",
    "        \n",
    "    with learn.distrib_ctx():\n",
    "        if fine_tune: learn.fine_tune(nepochs, lr)\n",
    "        else: learn.fit_one_cycle(nepochs, lr)\n",
    "    \n",
    "    return learn\n",
    "\n",
    "\n",
    "imports='''\n",
    "from utils import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "need='get_dls_basic get_dls_general path'\n",
    "ngpus=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base case\n",
    "nepochs, lr = 5, 3e-3\n",
    "learn = in_torchddp(ngpus, train_imgnette_basic, nepochs, lr, imports=imports, need=need)\n",
    "\n",
    "# Then use normalization\n",
    "nepochs, lr = 5, 3e-3\n",
    "dls_bs, dls_size = 64, 224\n",
    "learn = in_torchddp(ngpus, train_imgnette_general, nepochs, lr, dls_bs, dls_size, \n",
    "                    imports=imports, need=need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07 Sizing & TTA . Progressive resizing\n",
    "\n",
    "Save the model after one stage, then fine tune at different sizes, starting from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progressive Resizing.  Save the intermediate model state\n",
    "\n",
    "nepochs, lr = 4, 3e-3\n",
    "dls_bs, dls_size = 128, 128\n",
    "learn = in_torchddp(ngpus, train_imgnette_general, nepochs, lr, dls_bs, dls_size,\n",
    "                    imports=imports, need=need)\n",
    "\n",
    "saved = '4epochs_128_128'\n",
    "learn.save(saved)\n",
    "\n",
    "# Then fine_tune at different size, starting from the saved state\n",
    "nepochs, lr = 5, 1e-3\n",
    "dls_bs, dls_size = 64, 224\n",
    "learn = in_torchddp(ngpus, train_imgnette_general, nepochs, lr, dls_bs, dls_size,\n",
    "                    load=saved, fine_tune=True, imports=imports, need=need)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}