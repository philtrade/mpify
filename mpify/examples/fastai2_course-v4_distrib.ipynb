{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## course-v4, fastai2 notebooks Distributed Training Versions Using `mpify`\n",
    "\n",
    "Below you'll find distributed training versions of those examples in 'Fastai2' course-v4 notebooks.\n",
    "\n",
    "[01_intro.ipynb](#01intro)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"01intro\"></a> 01_intro.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to train cnn on multiple GPUs\n",
    "from mpify import *\n",
    "\n",
    "imports='''from utils import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "from fastai2.vision.all import *\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "\n",
    "def is_cat(x): return x[0].isupper()\n",
    "    \n",
    "def train_cnn():\n",
    "\n",
    "    dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224))\n",
    "\n",
    "    learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "    with learn.distrib_ctx():\n",
    "        learn.fine_tune(4)\n",
    "    \n",
    "    return learn\n",
    "\n",
    "ngpus = 3\n",
    "\n",
    "learn = in_torchddp(ngpus, train_cnn, imports=imports, need=\"path is_cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to train unet on multiple GPUs\n",
    "from mpify import in_torchddp\n",
    "\n",
    "imports='''from utils import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "from fastai2.vision.all import *\n",
    "    \n",
    "def train_unet():\n",
    "    path = untar_data(URLs.CAMVID_TINY)\n",
    "    dls = SegmentationDataLoaders.from_label_func(\n",
    "        path, bs=8, fnames = get_image_files(path/\"images\"),\n",
    "        label_func = lambda o: path/'labels'/f'{o.stem}_P{o.suffix}',\n",
    "        codes = np.loadtxt(path/'codes.txt', dtype=str)\n",
    "    )\n",
    "\n",
    "    learn = unet_learner(dls, resnet34)\n",
    "    with learn.distrib_ctx(): learn.fine_tune(20)\n",
    "    return learn\n",
    "\n",
    "ngpus = 3\n",
    "learn = in_torchddp(ngpus, train_unet, imports=imports)\n",
    "learn.show_results(max_n=6, figsize=(7,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train text classifier on multiple GPUs\n",
    "\n",
    "from mpify import in_torchddp\n",
    "\n",
    "imports='''from utils import *\n",
    "from fastai2.text.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "def train_imdb_classifier():\n",
    "    \n",
    "    dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test', bs=96)\n",
    "    learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\n",
    "    \n",
    "    import os\n",
    "    if int(os.environ['WORLD_SIZE']) > 1 and torch.__version__.startswith(\"1.4\"): DistributedTrainer.fup = True\n",
    "        \n",
    "    with learn.distrib_ctx(): learn.fine_tune(4, 1e-2)\n",
    "    return learn\n",
    "\n",
    "# To train on 3 GPUs with distributed data parallel\n",
    "learn = in_torchddp(3, train_imdb_classifier, imports=imports)\n",
    "\n",
    "learn.predict(\"I really liked that movie!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train tabular in multiple GPUs\n",
    "\n",
    "from mpify import in_torchddp\n",
    "\n",
    "imports='''from utils import *\n",
    "from fastai2.tabular.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "def train_tabular():\n",
    "    path = untar_data(URLs.ADULT_SAMPLE)\n",
    "\n",
    "    dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n",
    "        cat_names = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                     'relationship', 'race'],\n",
    "        cont_names = ['age', 'fnlwgt', 'education-num'],\n",
    "        procs = [Categorify, FillMissing, Normalize])\n",
    "\n",
    "    learn = tabular_learner(dls, metrics=accuracy)\n",
    "    with learn.distrib_ctx():\n",
    "        learn.fit_one_cycle(3)\n",
    "    return learn\n",
    "\n",
    "# To train on 3 GPUs with distributed data parallel\n",
    "learn = in_torchddp(3, train_tabular, imports=imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train collab in multiple GPUs\n",
    "\n",
    "from mpify import in_torchddp\n",
    "\n",
    "imports='''from utils import *\n",
    "from fastai2.collab import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "def train_collab():\n",
    "    path = untar_data(URLs.ML_SAMPLE)\n",
    "    dls = CollabDataLoaders.from_csv(path/'ratings.csv')\n",
    "    learn = collab_learner(dls, y_range=(0.5,5.5))\n",
    "    with learn.distrib_ctx():\n",
    "        learn.fine_tune(40)\n",
    "    return learn\n",
    "\n",
    "# To train on 3 GPUs with distributed data parallel\n",
    "learn = in_torchddp(3, train_collab, imports=imports)\n",
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"05petbreeds\"></a> 05_pet_breeds.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T10:13:21.085172Z",
     "start_time": "2020-07-19T10:13:21.047397Z"
    }
   },
   "outputs": [],
   "source": [
    "from mpify import in_torchddp\n",
    "ngpus = 3\n",
    "imports='''\n",
    "from utils import *\n",
    "from fastai2.data import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "def fine_tune(learn:Learner, nepochs, *args, **kwargs):\n",
    "    with learn.distrib_ctx(): learn.fine_tune(nepochs, *args, **kwargs)\n",
    "    return learn\n",
    "    \n",
    "def one_cycle(learn:Learner, nepochs, *args, **kwargs):\n",
    "    with learn.distrib_ctx(): learn.fit_one_cycle(nepochs, *args, **kwargs)\n",
    "    return learn\n",
    "\n",
    "\n",
    "def trainer(train_fn, nepochs, *args, load:str=None, **kwargs):\n",
    "\n",
    "    path = untar_data(URLs.PETS)\n",
    "\n",
    "    pets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                     get_items = get_image_files, \n",
    "                     splitter  = RandomSplitter(seed=42),\n",
    "                     get_y     = using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n",
    "                     item_tfms = Resize(460),\n",
    "                     batch_tfms= aug_transforms(size=224, min_scale=0.75))\n",
    "    dls = pets.dataloaders(path/\"images\")\n",
    "    \n",
    "    learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "    \n",
    "    if load:\n",
    "        learn.load(load)\n",
    "        print(f'Model and state loaded from {load}')\n",
    "\n",
    "    learn = train_fn(learn, nepochs, *args, **kwargs)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T10:13:21.085172Z",
     "start_time": "2020-07-19T10:13:21.047397Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = in_torchddp(ngpus, trainer, fine_tune, 1, base_lr=0.1, imports=imports, need=\"fine_tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_min,lr_steep = learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: learn.fine_tune(2, base_lr=3e-3)\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer, fine_tune, 2, base_lr=3e-3,\n",
    "                    imports=imports, need=\"fine_tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: learn.fit_one_cycle(3, 3e-3)\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer, one_cycle, 3, 3e-3,\n",
    "                    imports=imports, need=\"one_cycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: learn.fit_one_cycle(6, lr_max=1e-5)\n",
    "\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer, one_cycle, 6, lr_max=1e-5,\n",
    "                    imports=imports, need=\"one_cycle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05 pets breeds: Discriminative Learning Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform:\n",
    "\n",
    "```python\n",
    "    learn.fit_one_cycle(3, 3e-3)\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(12, lr_max=slice(1e-6,1e-4))\n",
    "```\n",
    "\n",
    "we need to *save the model state* before the second `fit_one_cycle()`, then tell `in_torchddp()` to load from that file using 'load=file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = in_torchddp(ngpus, trainer, one_cycle, 3, 3e-3,\n",
    "                    imports=imports, need=\"one_cycle\")\n",
    "learn.unfreeze()\n",
    "learn.save(\"after_unfreeze\", with_opt=True, pickle_protocol=4)\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer, one_cycle, 12, lr_max=slice(1e-6,1e-4),\n",
    "                    load=\"after_unfreeze\", imports=imports, need=\"one_cycle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05 pets breeds: Deeper Architectures\n",
    "\n",
    "To do:\n",
    "```python\n",
    "from fastai2.callback.fp16 import *\n",
    "learn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16()\n",
    "learn.fine_tune(6, freeze_epochs=3)\n",
    "```\n",
    "\n",
    "We modify `trainer()` to write a new function `trainer_fp16_resnet50()`, replace `resnet34` with `resnet50`, and add `.to_fp16()`.  Then pass it to `in_torchddp()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer_fp16_resnet50(train_fn, nepochs, *args, load:str=None, **kwargs):\n",
    "\n",
    "    path = untar_data(URLs.PETS)\n",
    "\n",
    "    pets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                     get_items = get_image_files, \n",
    "                     splitter  = RandomSplitter(seed=42),\n",
    "                     get_y     = using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n",
    "                     item_tfms = Resize(460),\n",
    "                     batch_tfms= aug_transforms(size=224, min_scale=0.75))\n",
    "    dls = pets.dataloaders(path/\"images\")\n",
    "    \n",
    "    # Use resnet50, and half precision.\n",
    "    learn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16()\n",
    "    \n",
    "    if load:\n",
    "        learn.load(load)\n",
    "        print(f'Model and state loaded from {load}')\n",
    "\n",
    "    learn = train_fn(learn, nepochs, *args, **kwargs)\n",
    "    return learn\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer_fp16_resnet50, fine_tune, 6, freeze_epochs=3,\n",
    "                    imports=imports, need=\"fine_tune\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
