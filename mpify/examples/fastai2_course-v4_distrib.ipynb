{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## course-v4, fastai2 notebooks Distributed Training Versions Using `mpify`\n",
    "\n",
    "Below you'll find distributed training versions of those examples in 'Fastai2' course-v4 notebooks.\n",
    "\n",
    "[01_intro.ipynb](#01intro)\n",
    "\n",
    "[05_pet_breeds.ipynb](#01petbreeds)\n",
    "\n",
    "[06 multicat.ipynb](#06multicat)\n",
    "\n",
    "[07 Sizing and TTA.ipynb](#07sizingtta)\n",
    "\n",
    "[08 Collab.ipynb](#08collab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"01intro\"></a> 01_intro.ipynb\n",
    "\n",
    "To train a `fastai2` learner on multiple processes, the `DataLoaders` must be re-created fresh on each process, because in its instantiation process, it would access the GPU, thus cannot be used in another process.\n",
    "\n",
    "Thus in all the examples here, both `DataBlock` and `DataLoaders` (often noted as `dls`) are all created inside the target function body.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to train cnn on multiple GPUs\n",
    "from mpify import *\n",
    "\n",
    "imports='''from utils import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "from fastai2.vision.all import *\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "\n",
    "def is_cat(x): return x[0].isupper()\n",
    "    \n",
    "def train_cnn():\n",
    "\n",
    "    dls = ImageDataLoaders.from_name_func(\n",
    "        path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "        label_func=is_cat, item_tfms=Resize(224))\n",
    "\n",
    "    learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "    with learn.distrib_ctx():\n",
    "        learn.fine_tune(4)\n",
    "    \n",
    "    return learn\n",
    "\n",
    "ngpus = 3\n",
    "\n",
    "learn = in_torchddp(ngpus, train_cnn, imports=imports, need=\"path is_cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to train unet on multiple GPUs\n",
    "from mpify import in_torchddp\n",
    "\n",
    "imports='''from utils import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "from fastai2.vision.all import *\n",
    "    \n",
    "def train_unet():\n",
    "    path = untar_data(URLs.CAMVID_TINY)\n",
    "    dls = SegmentationDataLoaders.from_label_func(\n",
    "        path, bs=8, fnames = get_image_files(path/\"images\"),\n",
    "        label_func = lambda o: path/'labels'/f'{o.stem}_P{o.suffix}',\n",
    "        codes = np.loadtxt(path/'codes.txt', dtype=str)\n",
    "    )\n",
    "\n",
    "    learn = unet_learner(dls, resnet34)\n",
    "    with learn.distrib_ctx(): learn.fine_tune(20)\n",
    "    return learn\n",
    "\n",
    "ngpus = 3\n",
    "learn = in_torchddp(ngpus, train_unet, imports=imports)\n",
    "learn.show_results(max_n=6, figsize=(7,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train text classifier on multiple GPUs\n",
    "\n",
    "from mpify import in_torchddp\n",
    "\n",
    "imports='''from utils import *\n",
    "from fastai2.text.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "def train_imdb_classifier():\n",
    "    \n",
    "    dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test', bs=96)\n",
    "    learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\n",
    "    \n",
    "    import os\n",
    "    if int(os.environ['WORLD_SIZE']) > 1 and torch.__version__.startswith(\"1.4\"): DistributedTrainer.fup = True\n",
    "        \n",
    "    with learn.distrib_ctx(): learn.fine_tune(4, 1e-2)\n",
    "    return learn\n",
    "\n",
    "# To train on 3 GPUs with distributed data parallel\n",
    "learn = in_torchddp(3, train_imdb_classifier, imports=imports)\n",
    "\n",
    "learn.predict(\"I really liked that movie!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train tabular in multiple GPUs\n",
    "\n",
    "from mpify import in_torchddp\n",
    "\n",
    "imports='''from utils import *\n",
    "from fastai2.tabular.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "def train_tabular():\n",
    "    path = untar_data(URLs.ADULT_SAMPLE)\n",
    "\n",
    "    dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n",
    "        cat_names = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                     'relationship', 'race'],\n",
    "        cont_names = ['age', 'fnlwgt', 'education-num'],\n",
    "        procs = [Categorify, FillMissing, Normalize])\n",
    "\n",
    "    learn = tabular_learner(dls, metrics=accuracy)\n",
    "    with learn.distrib_ctx():\n",
    "        learn.fit_one_cycle(3)\n",
    "    return learn\n",
    "\n",
    "# To train on 3 GPUs with distributed data parallel\n",
    "learn = in_torchddp(3, train_tabular, imports=imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train collab in multiple GPUs\n",
    "\n",
    "from mpify import in_torchddp\n",
    "\n",
    "imports='''from utils import *\n",
    "from fastai2.collab import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "def train_collab():\n",
    "    path = untar_data(URLs.ML_SAMPLE)\n",
    "    dls = CollabDataLoaders.from_csv(path/'ratings.csv')\n",
    "    learn = collab_learner(dls, y_range=(0.5,5.5))\n",
    "    with learn.distrib_ctx():\n",
    "        learn.fine_tune(40)\n",
    "    return learn\n",
    "\n",
    "# To train on 3 GPUs with distributed data parallel\n",
    "learn = in_torchddp(3, train_collab, imports=imports)\n",
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"05petbreeds\"></a> 05_pet_breeds.ipynb\n",
    "\n",
    "In the `trainer` function for Chapter 5 \"Pet Breeds\", let's add two functionalities:\n",
    "\n",
    "1. It redirects the actual training to another function that takes a `learner` object, # of epochs, and other parameters.  This way, we can use the same `trainer()` body but calls different `learner` training methods, sometimes `fit_one_cycle()`, other times `fine_tune()`.\n",
    "\n",
    "2. Add `load=filename` to load up a model state to a freshly created learner object.  It'll become useful in the section \"Discriminative Learning Rates\" that follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T10:13:21.085172Z",
     "start_time": "2020-07-19T10:13:21.047397Z"
    }
   },
   "outputs": [],
   "source": [
    "from mpify import in_torchddp\n",
    "ngpus = 3\n",
    "imports='''\n",
    "from utils import *\n",
    "from fastai2.data import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "def fine_tune(learn:Learner, nepochs, *args, **kwargs):\n",
    "    with learn.distrib_ctx(): learn.fine_tune(nepochs, *args, **kwargs)\n",
    "    return learn\n",
    "    \n",
    "def one_cycle(learn:Learner, nepochs, *args, **kwargs):\n",
    "    with learn.distrib_ctx(): learn.fit_one_cycle(nepochs, *args, **kwargs)\n",
    "    return learn\n",
    "\n",
    "\n",
    "def trainer(train_fn, nepochs, *args, load:str=None, **kwargs):\n",
    "\n",
    "    path = untar_data(URLs.PETS)\n",
    "\n",
    "    pets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                     get_items = get_image_files, \n",
    "                     splitter  = RandomSplitter(seed=42),\n",
    "                     get_y     = using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n",
    "                     item_tfms = Resize(460),\n",
    "                     batch_tfms= aug_transforms(size=224, min_scale=0.75))\n",
    "    dls = pets.dataloaders(path/\"images\")\n",
    "    \n",
    "    learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "    \n",
    "    if load:\n",
    "        learn.load(load)\n",
    "        print(f'Model and state loaded from {load}')\n",
    "\n",
    "    learn = train_fn(learn, nepochs, *args, **kwargs)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T10:13:21.085172Z",
     "start_time": "2020-07-19T10:13:21.047397Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = in_torchddp(ngpus, trainer, fine_tune, 1, base_lr=0.1, imports=imports, need=\"fine_tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_min,lr_steep = learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: learn.fine_tune(2, base_lr=3e-3)\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer, fine_tune, 2, base_lr=3e-3,\n",
    "                    imports=imports, need=\"fine_tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: learn.fit_one_cycle(3, 3e-3)\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer, one_cycle, 3, 3e-3,\n",
    "                    imports=imports, need=\"one_cycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: learn.fit_one_cycle(6, lr_max=1e-5)\n",
    "\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer, one_cycle, 6, lr_max=1e-5,\n",
    "                    imports=imports, need=\"one_cycle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05 pets breeds: Discriminative Learning Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform:\n",
    "\n",
    "```python\n",
    "    learn.fit_one_cycle(3, 3e-3)\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(12, lr_max=slice(1e-6,1e-4))\n",
    "```\n",
    "\n",
    "we need to *save the model state* before the second `fit_one_cycle()`, then tell `in_torchddp()` to load from that file using 'load=file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = in_torchddp(ngpus, trainer, one_cycle, 3, 3e-3,\n",
    "                    imports=imports, need=\"one_cycle\")\n",
    "learn.unfreeze()\n",
    "learn.save(\"after_unfreeze\", with_opt=True, pickle_protocol=4)\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer, one_cycle, 12, lr_max=slice(1e-6,1e-4),\n",
    "                    load=\"after_unfreeze\", imports=imports, need=\"one_cycle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05 pets breeds: Deeper Architectures\n",
    "\n",
    "To do:\n",
    "```python\n",
    "from fastai2.callback.fp16 import *\n",
    "learn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16()\n",
    "learn.fine_tune(6, freeze_epochs=3)\n",
    "```\n",
    "\n",
    "We modify `trainer()` to write a new function `trainer_fp16_resnet50()`, replace `resnet34` with `resnet50`, and add `.to_fp16()`.  Then pass it to `in_torchddp()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer_fp16_resnet50(train_fn, nepochs, *args, load:str=None, **kwargs):\n",
    "\n",
    "    path = untar_data(URLs.PETS)\n",
    "\n",
    "    pets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                     get_items = get_image_files, \n",
    "                     splitter  = RandomSplitter(seed=42),\n",
    "                     get_y     = using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n",
    "                     item_tfms = Resize(460),\n",
    "                     batch_tfms= aug_transforms(size=224, min_scale=0.75))\n",
    "    dls = pets.dataloaders(path/\"images\")\n",
    "    \n",
    "    # Use resnet50, and half precision.\n",
    "    learn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16()\n",
    "    \n",
    "    if load:\n",
    "        learn.load(load)\n",
    "        print(f'Model and state loaded from {load}')\n",
    "\n",
    "    learn = train_fn(learn, nepochs, *args, **kwargs)\n",
    "    return learn\n",
    "\n",
    "learn = in_torchddp(ngpus, trainer_fp16_resnet50, fine_tune, 6, freeze_epochs=3,\n",
    "                    imports=imports, need=\"fine_tune\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name='06multicat'></a> 06 Multicat\n",
    "\n",
    "The examples in Chapter 6 \"Multi-Label Classification\", `learn` object is built from\n",
    "pieces across many cells. \n",
    "\n",
    "`DataBlock` object needs `path`, and a few other functions: `get_x, get_y, splitter`, and `dls` needs `df`.  So we group some of them together in `need=`.\n",
    "\n",
    "I do notice accuracy degradation using the same 3 epochs, of `0.81`, as oppose to the `0.95` range in the book.\n",
    "\n",
    "So what can we do?  Save the model after the first training, then use `load=filename` flag, tweak `nepochs` and `freeze_epochs=` values and call `in_torchddp()` again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are defined earlier in the notebook:\n",
    "\n",
    "path = untar_data(URLs.PASCAL_2007)\n",
    "df = pd.read_csv(path/'train.csv')\n",
    "\n",
    "def get_x(r): return path/'train'/r['fname']\n",
    "def get_y(r): return r['labels'].split(' ')\n",
    "def splitter(df):\n",
    "    train = df.index[~df['is_valid']].tolist()\n",
    "    valid = df.index[df['is_valid']].tolist()\n",
    "    return train,valid\n",
    "\n",
    "# to perform those trainings in DDP\n",
    "\n",
    "from mpify import in_torchddp\n",
    "ngpus = 3\n",
    "\n",
    "def train_multicat(nepochs, *args, load:str=None, **kwargs):\n",
    "    dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n",
    "                   splitter=splitter,\n",
    "                   get_x=get_x, \n",
    "                   get_y=get_y,\n",
    "                   item_tfms = RandomResizedCrop(128, min_scale=0.35))\n",
    "    dls = dblock.dataloaders(df)\n",
    "    \n",
    "    learn = cnn_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.2))\n",
    "    \n",
    "    if load: learn.load(load); print(f'Model and state loaded from {load}')\n",
    "\n",
    "    with learn.distrib_ctx():\n",
    "        learn.fine_tune(nepochs, *args, **kwargs)\n",
    "        \n",
    "    return learn\n",
    "        \n",
    "imports='''\n",
    "from utils import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "need=\"path df get_x get_y splitter\"\n",
    "\n",
    "learn = in_torchddp(ngpus, train_multicat, 3, base_lr=3e-3, freeze_epochs=4,\n",
    "                    imports=imports, need=need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The next training uses a different dataset `BIWI_HEAD_POSE`, and will need `get_ctr()`, `numpy`, `cal`. And I missed `img2pose` in the first pass, causing a `NameError` exception be thrown.  Simply add it to `need=`.\n",
    "\n",
    "The same trick with `load=` will help improve the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.BIWI_HEAD_POSE)\n",
    "\n",
    "def img2pose(x): return Path(f'{str(x)[:-7]}pose.txt')\n",
    "\n",
    "cal = np.genfromtxt(path/'01'/'rgb.cal', skip_footer=6)\n",
    "def get_ctr(f):\n",
    "    ctr = np.genfromtxt(img2pose(f), skip_header=3)\n",
    "    c1 = ctr[0] * cal[0][0]/ctr[2] + cal[0][2]\n",
    "    c2 = ctr[1] * cal[1][1]/ctr[2] + cal[1][2]\n",
    "    return tensor([c1,c2])\n",
    "\n",
    "def train_biwi(nepochs, *args, load:str=None, **kwargs):\n",
    "    biwi = DataBlock(\n",
    "        blocks=(ImageBlock, PointBlock),\n",
    "        get_items=get_image_files,\n",
    "        get_y=get_ctr,\n",
    "        splitter=FuncSplitter(lambda o: o.parent.name=='13'),\n",
    "        batch_tfms=[*aug_transforms(size=(240,320)), \n",
    "                    Normalize.from_stats(*imagenet_stats)])\n",
    "\n",
    "    dls = biwi.dataloaders(path)\n",
    "\n",
    "    learn = cnn_learner(dls, resnet18, y_range=(-1,1))\n",
    "    if load: learn.load(load); print(f'Model and state loaded from {load}')\n",
    "\n",
    "    lr = 1e-2\n",
    "    with learn.distrib_ctx(): learn.fine_tune(nepochs, lr)\n",
    "    return learn\n",
    "\n",
    "imports='''\n",
    "from utils import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.distributed import *\n",
    "improt numpy as np\n",
    "'''\n",
    "\n",
    "need=\"path cal get_ctr img2pose\"\n",
    "\n",
    "learn = in_torchddp(ngpus, train_biwi, 3, imports=imports, need=need)\n",
    "\n",
    "# Not satisfied with the accuracy?  Save then train 5 more epochs, starting from the current state\n",
    "learn.save('biwi_after3')\n",
    "learn = in_torchddp(ngpus, train_biwi, 5, load='biwi_after3', imports=imports, need=need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name='07sizingtta'></a> 07 Sizing and TTA\n",
    "\n",
    "In this chapter, imagenette dataset is trained with incremental optimization.  First add normalization, then progressive resizing and fine tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpify import in_torchddp\n",
    "from fastai2.vision.all import *\n",
    "path = untar_data(URLs.IMAGENETTE)\n",
    "\n",
    "\n",
    "def get_dls_64_224_no_normalize():\n",
    "    dblock = DataBlock(blocks=(ImageBlock(), CategoryBlock()),\n",
    "                       get_items=get_image_files,\n",
    "                       get_y=parent_label,\n",
    "                       item_tfms=Resize(460),\n",
    "                       batch_tfms=aug_transforms(size=224, min_scale=0.75))\n",
    "    dls = dblock.dataloaders(path, bs=64)\n",
    "    return dls\n",
    "\n",
    "def train_imgnette_64_224_no_normalize(nepochs, lr, *args, **kwargs):\n",
    "    dls = get_dls_64_224_no_normalize() \n",
    "    model = xresnet50()\n",
    "    learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n",
    "    \n",
    "    with learn.distrib_ctx():\n",
    "        learn.fit_one_cycle(nepochs, lr)\n",
    "    \n",
    "    return learn\n",
    "\n",
    "# The following pair will normalize batches, and allow custom sizes.\n",
    "def get_dls(bs, size):\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                   get_items=get_image_files,\n",
    "                   get_y=parent_label,\n",
    "                   item_tfms=Resize(460),\n",
    "                   batch_tfms=[*aug_transforms(size=size, min_scale=0.75),\n",
    "                               Normalize.from_stats(*imagenet_stats)])\n",
    "    return dblock.dataloaders(path, bs=bs)\n",
    "\n",
    "def train_imgnette_normalize(nepochs, lr, dls_bs, dls_size, *args,\n",
    "                             fine_tune:bool=False, load:str=None, **kwargs):\n",
    "    dls = get_dls(dls_bs, dls_size) \n",
    "    model = xresnet50()\n",
    "    learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n",
    "    \n",
    "    if load:\n",
    "        learn.load(load)\n",
    "        print(f\"Model state loaded from {load}\")\n",
    "        \n",
    "    with learn.distrib_ctx():\n",
    "        if fine_tune: learn.fine_tune(nepochs, lr)\n",
    "        else: learn.fit_one_cycle(nepochs, lr)\n",
    "    \n",
    "    return learn\n",
    "\n",
    "\n",
    "imports='''\n",
    "from utils import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "ngpus=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs, lr = 5, 3e-3\n",
    "need='get_dls_64_224_no_normalize path'\n",
    "learn = in_torchddp(ngpus, train_imgnette_64_224_no_normalize, 1, 3e-3,\n",
    "                    imports=imports, need=need)\n",
    "\n",
    "# Then use normalization\n",
    "nepochs, lr = 5, 3e-3\n",
    "dls_bs, dls_size = 64, 224\n",
    "need='get_dls path'\n",
    "learn = in_torchddp(ngpus, train_imgnette_normalize, 5, 3e-3, dls_bs, dls_size,\n",
    "                    imports=imports, need=need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07 Sizing & TTA . Progressive resizing\n",
    "\n",
    "Save the model after one stage, then fine tune at different sizes, starting from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progressive Resizing.  Save the intermediate model state\n",
    "need='get_dls path'\n",
    "\n",
    "nepochs, lr = 4, 3e-3\n",
    "dls_bs, dls_size = 128, 128\n",
    "learn = in_torchddp(ngpus, train_imgnette_normalize, nepochs, lr, dls_bs, dls_size,\n",
    "                    imports=imports, need=need)\n",
    "\n",
    "learn.save('4epochs_128_128')\n",
    "\n",
    "# Then fine_tune at different size, starting from the saved state\n",
    "nepochs, lr = 5, 1e-3\n",
    "dls_bs, dls_size = 64, 224\n",
    "learn = in_torchddp(ngpus, train_imgnette_normalize, nepochs, lr, dls_bs, dls_size,\n",
    "                    load='4epochs_128_128', fine_tune=True, imports=imports, need=need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name='08collab'></a> 08 Collab\n",
    "\n",
    "In the first two training examples in notebook 08_collab, variables that depends on `dls` we move them inside the target function.  Those created before `dls`, we can pass them in as `need=`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from fastai2.collab import *\n",
    "from fastai2.tabular.all import *\n",
    "\n",
    "path = untar_data(URLs.ML_100k)\n",
    "ratings = pd.read_csv(path/'u.data', delimiter='\\t', header=None,\n",
    "                      names=['user','movie','rating','timestamp'])\n",
    "\n",
    "movies = pd.read_csv(path/'u.item',  delimiter='|', encoding='latin-1',\n",
    "                     usecols=(0,1), names=('movie','title'), header=None)\n",
    "\n",
    "ratings = ratings.merge(movies)\n",
    "\n",
    "class DotProduct(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        return (users * movies).sum(dim=1)\n",
    "\n",
    "def train_dotproduct(nepochs, *args, load:str=None, **kwargs):\n",
    "    dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64)\n",
    "    \n",
    "    n_users  = len(dls.classes['user'])\n",
    "    n_movies = len(dls.classes['title'])\n",
    "    n_factors = 5\n",
    "    user_factors = torch.randn(n_users, n_factors)\n",
    "    movie_factors = torch.randn(n_movies, n_factors)\n",
    "\n",
    "    model = DotProduct(n_users, n_movies, 50)\n",
    "    learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "    \n",
    "    if load: learn.load(load); print(f'Model and state loaded from {load}')\n",
    "\n",
    "    with learn.distrib_ctx(): learn.fit_one_cycle(nepochs, *args)\n",
    "    return learn\n",
    "\n",
    "from mpify import in_torchddp\n",
    "ngpus = 3\n",
    "\n",
    "imports='''\n",
    "from utils import *\n",
    "from fastai2.collab import *\n",
    "from fastai2.tabular.all import *\n",
    "from fastai2.distributed import *\n",
    "'''\n",
    "\n",
    "need=\"path ratings DotProductClass\"\n",
    "\n",
    "DotProductClass = DotProduct\n",
    "learn = in_torchddp(ngpus, train_dotproduct, 5, 5e-3, imports=imports, need=need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the `DotProduct` class, validation loss drops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new dotproduct class\n",
    "class DotProduct(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        return sigmoid_range((users * movies).sum(dim=1), *self.y_range)\n",
    "\n",
    "    \n",
    "DotProductClass = DotProduct # Update DotProductClass pointer\n",
    "learn = in_torchddp(ngpus, train_dotproduct, 5, 5e-3, imports=imports, need=need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Try a different DotProduct class: `DotProductBias`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductBias(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.user_bias = Embedding(n_users, 1)\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        self.movie_bias = Embedding(n_movies, 1)\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        res = (users * movies).sum(dim=1, keepdim=True)\n",
    "        res += self.user_bias(x[:,0]) + self.movie_bias(x[:,1])\n",
    "        return sigmoid_range(res, *self.y_range)\n",
    "    \n",
    "DotProductClass=DotProductBias\n",
    "\n",
    "learn = in_torchddp(ngpus, train_dotproduct, 5, 5e-3, imports=imports, need=need)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 08 Collab . Weight Decay, and Create Our Own Embedding Module\n",
    "\n",
    "First try adding weight decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DotProductClass=DotProductBias\n",
    "learn = in_torchddp(ngpus, train_dotproduct, 5, 5e-3, wd=0.1, imports=imports, need=need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create our own embedding module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Our Own Embedding ModuleÂ¶\n",
    "def create_params(size):\n",
    "    return nn.Parameter(torch.zeros(*size).normal_(0, 0.01))\n",
    "\n",
    "class DotProductBias(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
    "        self.user_factors = create_params([n_users, n_factors])\n",
    "        self.user_bias = create_params([n_users])\n",
    "        self.movie_factors = create_params([n_movies, n_factors])\n",
    "        self.movie_bias = create_params([n_movies])\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors[x[:,0]]\n",
    "        movies = self.movie_factors[x[:,1]]\n",
    "        res = (users*movies).sum(dim=1)\n",
    "        res += self.user_bias[x[:,0]] + self.movie_bias[x[:,1]]\n",
    "        return sigmoid_range(res, *self.y_range)\n",
    "\n",
    "DotProductClass=DotProductBias\n",
    "need = need+' create_params'  # add create_params\n",
    "learn = in_torchddp(ngpus, train_dotproduct, 5, 5e-3, wd=0.1, imports=imports, need=need)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tedious steps are all abstracted away in `collab_learner`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_collab(nepochs, *args, load:str=None, **kwargs):\n",
    "    dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64)\n",
    "\n",
    "    learn = collab_learner(dls, n_factors=50, y_range=(0, 5.5))\n",
    "    \n",
    "    if load: learn.load(load); print(f'Model and state loaded from {load}')\n",
    "\n",
    "    with learn.distrib_ctx(): learn.fit_one_cycle(nepochs, *args)\n",
    "    return learn\n",
    "\n",
    "learn = in_torchddp(ngpus, train_collab, 5, 5e-3, wd=0.1, imports=imports, need=need)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 08 Collab . Boostraping Collab Model\n",
    "\n",
    "Build learner in 2 different ways, from a CollabNN, or the default nn:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T19:35:25.701175Z",
     "start_time": "2020-07-19T19:35:25.691498Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-75f9e8a4d577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "embs = get_emb_sz(learn.dls)\n",
    "\n",
    "class CollabNN(Module):\n",
    "    def __init__(self, user_sz, item_sz, y_range=(0,5.5), n_act=100):\n",
    "        self.user_factors = Embedding(*user_sz)\n",
    "        self.item_factors = Embedding(*item_sz)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(user_sz[1]+item_sz[1], n_act),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_act, 1))\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embs = self.user_factors(x[:,0]),self.item_factors(x[:,1])\n",
    "        x = self.layers(torch.cat(embs, dim=1))\n",
    "        return sigmoid_range(x, *self.y_range)\n",
    "\n",
    "def train_bootstrap(nepochs, *args, load:str=None, **kwargs):\n",
    "    dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64)\n",
    "\n",
    "    model = CollabNN(*embs)\n",
    "    \n",
    "    learn = Learner(dls, model, loss_func=MSELossFlat())    \n",
    "    if load: learn.load(load); print(f'Model and state loaded from {load}')\n",
    "\n",
    "    with learn.distrib_ctx(): learn.fit_one_cycle(nepochs, *args)\n",
    "    return learn\n",
    "\n",
    "def train_collab_learner(nepochs, *args, load:str=None, **kwargs):\n",
    "    dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64)\n",
    "    \n",
    "    learn = collab_learner(dls, use_nn=True, y_range=(0, 5.5), layers=[100,50])    \n",
    "    if load: learn.load(load); print(f'Model and state loaded from {load}')\n",
    "\n",
    "    with learn.distrib_ctx(): learn.fit_one_cycle(nepochs, *args)\n",
    "    return learn\n",
    "\n",
    "need='ratings CollabNN embs'\n",
    "learn = in_torchddp(ngpus, train_bootstrap, 5, 5e-3, wd=0.1, imports=imports, need=need)\n",
    "\n",
    "learn = in_torchddp(ngpus, train_collab_learner, 5, 5e-3, wd=0.1, imports=imports, need=need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 NLP\n",
    "\n",
    "The `langauge_model_learner` in `fastai2` does not quite work yet in distributed training.  It fails at collating batches, trying to stack two batches of different dimensions:\n",
    "```python\n",
    "~/Dropbox/fastai2/fastai2/data/load.py in <listcomp>(.0)\n",
    "     44     b = t[0]\n",
    "     45     return (default_collate(t) if isinstance(b, _collate_types)\n",
    "---> 46             else type(t[0])([fa_collate(s) for s in zip(*t)]) if isinstance(b, Sequence)\n",
    "     47             else default_collate(t))\n",
    "     48 \n",
    "\n",
    "~/Dropbox/fastai2/fastai2/data/load.py in fa_collate(t)\n",
    "     43 def fa_collate(t):\n",
    "     44     b = t[0]\n",
    "---> 45     return (default_collate(t) if isinstance(b, _collate_types)\n",
    "     46             else type(t[0])([fa_collate(s) for s in zip(*t)]) if isinstance(b, Sequence)\n",
    "     47             else default_collate(t))\n",
    "\n",
    "~/miniconda/envs/fastai2/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py in default_collate(batch)\n",
    "     53             storage = elem.storage()._new_shared(numel)\n",
    "     54             out = elem.new(storage)\n",
    "---> 55         return torch.stack(batch, 0, out=out)\n",
    "     56     elif elem_type.__module__ == 'numpy' and elem_type.__name__ != 'str_' \\\n",
    "     57             and elem_type.__name__ != 'string_':\n",
    "\n",
    "RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 218 and 308 in dimension 1 at /pytorch/aten/src/TH/generic/THTensor.cpp:612\n",
    "```\n",
    "\n",
    "But text classifier can be trained in DDP, see `fastai2/nbs/examples/train_trainimdbclassifier.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}